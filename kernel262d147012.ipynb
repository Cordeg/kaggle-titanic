{"cells":[{"metadata":{"_uuid":"2ad515b1-de78-45b5-ae23-e0bfd01d9227","_cell_guid":"1db4e51b-e562-45ff-855a-7fb5ca4f2744","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":19,"outputs":[{"output_type":"stream","text":"/kaggle/input/titanic/gender_submission.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/train.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = np.array(range(10))\na.reshape([-1,1])","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"array([[0],\n       [1],\n       [2],\n       [3],\n       [4],\n       [5],\n       [6],\n       [7],\n       [8],\n       [9]])"},"metadata":{}}]},{"metadata":{"_uuid":"7c46871b-4d9a-49af-9fcd-076f8ef1ccbc","_cell_guid":"4c8fae3b-1a2b-4c10-9623-8cf78541433c","trusted":true},"cell_type":"code","source":"import csv\nfrom sklearn.model_selection import train_test_split\n\ninputdir = \"/kaggle/input/titanic\"\n# inputdir = \"./input\"\n\ntrain_dirname = os.path.join(inputdir, 'train.csv')\ntest_dirname = os.path.join(inputdir, 'test.csv')\n\nclass InputData(object):\n    \n    def __init__(self, dirname):\n        self.variables, self.data = self.load_data(dirname)\n                \n    def load_data(self, dirname):\n        with open(train_dirname, 'r') as f:\n            reader = csv.reader(f)\n            contents = list(reader)\n        \n        variables = contents[0]\n        data = np.array(contents[1:])\n        \n        return variables, data\n    \n    \nclass MyInputData(InputData):\n    \n    def __init__(self, dirname):\n        super().__init__(dirname)\n        \n        # variables to use my model.\n        # omit ['PassengerId', 'Name', 'Ticket', 'Cabin']\n        self.used_variables = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n        \n    def get_row(self, var):\n        transposed_data = self.data.transpose()\n        data_row = transposed_data[self.variables.index(var)]\n\n        if var == 'Survived':\n            data_row = [int(_) for _ in data_row]\n        elif var == 'Sex':\n            d = {'female':0, 'male':1, '': 2}\n            data_row = [d[_] for _ in data_row]\n        elif var == 'Embarked':\n            d = {'C':0, 'Q':1, 'S': 2, '': 3}\n            data_row = [d[_] for _ in data_row]\n        elif var in ['Pclass', 'SibSp', 'Parch']:\n            data_row = [int(_) for _ in data_row]\n        else:\n            # 今後の改善点：ゴミデータを含む場合は除去したした方が良い。\n            data_row = [float(_) if _!='' else 0 for _ in data_row]        \n\n        return np.array(data_row)\n    \n    def get_labels(self):\n        var = 'Survived'\n        if var in self.variables:\n            return self.get_row(var)\n        else:\n            raise Exception('No labels exists.')\n    \n    def get_array(self):\n        data_array = []\n        for variable in self.used_variables:\n            data_array.append(self.get_row(variable))\n\n        return np.array(data_array).transpose()\n    \n    def train_test_split(self, shuffle=True):\n        labels = self.get_labels()\n        # list to transposed 1d array: [x, y, z] -> [[x], [y], [z], ...]\n        labels = labels.reshape([-1,1])\n        \n        data_array = self.get_array()\n        \n        labels_and_data = np.hstack([labels, data_array])\n        train_labels_and_data, test_labels_and_data = train_test_split(labels_and_data, shuffle=shuffle)\n        \n        train_labels = train_labels_and_data[:, 0]\n        train_data = train_labels_and_data[:, 1:]\n        test_labels = test_labels_and_data[:, 0]\n        test_data = test_labels_and_data[:, 1:]\n        \n        # cast from float to int\n        train_labels = train_labels.astype(int)\n        test_labels = test_labels.astype(int)\n        \n        return train_labels, train_data, test_labels, test_data\n        \n\n    \ninput_data = MyInputData(train_dirname)\nlabels = input_data.get_labels()\ndata_array = input_data.get_array()\n\n# test\nprint(\"Labels:\", labels[:10])\nprint(input_data.used_variables)\nprint(data_array[0])\nprint(data_array[1])\ntral, trad, tesl, tesd = input_data.train_test_split()\nprint(tral.shape, trad.shape, tesl.shape, tesd.shape)\nprint(tral[:10])","execution_count":66,"outputs":[{"output_type":"stream","text":"Labels: [0 1 1 1 0 0 0 0 1 1]\n['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n[ 3.    1.   22.    1.    0.    7.25  2.  ]\n[ 1.      0.     38.      1.      0.     71.2833  0.    ]\n(668,) (668, 7) (223,) (223, 7)\n[1 1 0 1 1 1 1 0 1 1]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import tree\n\nbest_score = 0.0\nbest_classifier = None\n\nfor depth in range(3, 11):\n    for _ in range(5):\n        train_labels, train_data, test_labels, test_data = input_data.train_test_split()\n\n        clf = tree.DecisionTreeClassifier(max_depth=depth)\n        clf = clf.fit(train_data, train_labels)\n        \n        predicted = clf.predict(test_data)\n        score = sum(predicted == test_labels) / len(test_labels)\n        if score > best_score:\n            best_score = score\n            best_classifier = clf\n            print(\"score:\", score)","execution_count":67,"outputs":[{"output_type":"stream","text":"score: 0.7488789237668162\nscore: 0.8161434977578476\nscore: 0.8295964125560538\nscore: 0.852017937219731\nscore: 0.8654708520179372\n","name":"stdout"}]},{"metadata":{"_uuid":"e558b477-f32e-411a-b7a8-71c1318ad1ca","_cell_guid":"d11e4284-46be-41d4-8a24-4227ba167c38","trusted":true},"cell_type":"code","source":"\"\"\"\nPclass: [1, 2, 3]\nSex: [0, 1, 2]\nAge: [0~19, 20~39, 40~59, 60~]\nSibSp: [0, 1, 2, 3, 4, 5~]\n...0~8\nParch: [0, 1, 2, 3, 4~]\n...0~6\n'Fare': [0~50, 50~100, 100~150, 150~200, 200~]\n...0~512\n...154までに869人/891人\n\"\"\"\npass","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_data = MyInputData(test_dirname)\ndata_array = input_data.get_array()\n\nids = input_data.get_row('PassengerId')\nids = [int(_) for _ in ids]\n\npredicted = clf.predict(data_array)\n\nout = list(zip(ids, predicted))\nprint(out[:10])","execution_count":70,"outputs":[{"output_type":"stream","text":"[(1, 0), (2, 1), (3, 1), (4, 1), (5, 0), (6, 0), (7, 0), (8, 0), (9, 1), (10, 1)]\n","name":"stdout"}]},{"metadata":{"_uuid":"9d87b787-9c42-471f-a798-b5f51649ba91","_cell_guid":"893f6bb0-f692-4389-b2dd-3436a2a89d9b","trusted":true},"cell_type":"code","source":"def write_result(dirname):\n    with open(dirname, 'w') as f:\n        writer = csv.writer(f)\n        writer.writerow([\"PassengerId\", \"Survived\"])\n        writer.writerows(out)\n        \nout_dirname = './out.txt'\n#write_result(dirname)","execution_count":69,"outputs":[]},{"metadata":{"_uuid":"35d7c2b6-9b1c-40e9-94d7-1abd26f941e7","_cell_guid":"469e3a21-9f8f-4475-90ad-c3b31a968204","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}